{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4420,"status":"ok","timestamp":1695620695383,"user":{"displayName":"‎박동초(엘텍공과대학 휴먼기계바이오공학부)","userId":"15051333855527272603"},"user_tz":-540},"id":"y91tViSBLV1H","outputId":"94cedaa7-8265-4722-d61f-94ef519ce5d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"y91tViSBLV1H"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IhXetreeLec3","outputId":"8b14b661-2294-4d45-f03e-df75dbfa9b87"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/2023/open\n"]}],"source":["import zipfile\n","import shutil\n","\n","%cd /content/drive/MyDrive/2023/open\n","\n","!unzip -qq \"/content/drive/MyDrive/2023/open.zip\""],"id":"IhXetreeLec3"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64746,"status":"ok","timestamp":1695614751919,"user":{"displayName":"‎박동초(엘텍공과대학 휴먼기계바이오공학부)","userId":"15051333855527272603"},"user_tz":-540},"id":"Gd9PB8sezC9X","outputId":"004495bb-0b2a-4184-ad28-9fa60fcddacf"},"outputs":[{"name":"stdout","output_type":"stream","text":["test_image : 1897\n","train_source_gt : 2194\n","train_source_image : 2194\n","train_target_image : 2923\n","val_source_gt : 466\n","val_source_image : 466\n"]}],"source":["import os\n","\n","test_image_path = \"/content/drive/MyDrive/2023/open/test_image\"\n","train_source_gt_path = \"/content/drive/MyDrive/2023/open/train_source_gt\"\n","train_source_image_path = \"/content/drive/MyDrive/2023/open/train_source_image\"\n","train_target_image_path = \"/content/drive/MyDrive/2023/open/train_target_image\"\n","val_source_gt_path = \"/content/drive/MyDrive/2023/open/val_source_gt\"\n","val_source_image_path = \"/content/drive/MyDrive/2023/open/val_source_image\"\n","\n","file_list1 = os.listdir(test_image_path)\n","file_list2 = os.listdir(train_source_gt_path)\n","file_list3 = os.listdir(train_source_image_path)\n","file_list4 = os.listdir(train_target_image_path)\n","file_list5 = os.listdir(val_source_gt_path)\n","file_list6 = os.listdir(val_source_image_path)\n","\n","file_count1 = len(file_list1)\n","file_count2 = len(file_list2)\n","file_count3 = len(file_list3)\n","file_count4 = len(file_list4)\n","file_count5 = len(file_list5)\n","file_count6 = len(file_list6)\n","\n","print('test_image :', file_count1)\n","print('train_source_gt :', file_count2)\n","print('train_source_image :', file_count3)\n","print('train_target_image :', file_count4)\n","print('val_source_gt :', file_count5)\n","print('val_source_image :', file_count6)"],"id":"Gd9PB8sezC9X"},{"cell_type":"markdown","metadata":{"id":"d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914"},"source":["## Import"],"id":"d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ad9b681e-370a-4cfa-a452-dd2d7f0cd77f"},"outputs":[],"source":["import os\n","import cv2\n","from PIL import Image\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","\n","from tqdm import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"id":"ad9b681e-370a-4cfa-a452-dd2d7f0cd77f"},{"cell_type":"markdown","metadata":{"id":"20ff3de5-0d0e-497b-ac75-d5179a3f65d3"},"source":["## Utils"],"id":"20ff3de5-0d0e-497b-ac75-d5179a3f65d3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"838e1d83-8670-407b-82f6-bf9652f58639"},"outputs":[],"source":["# RLE 인코딩 함수\n","def rle_encode(mask):\n","    pixels = mask.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)"],"id":"838e1d83-8670-407b-82f6-bf9652f58639"},{"cell_type":"markdown","metadata":{"id":"be76a29e-e9c2-411a-a569-04166f074184"},"source":["## Custom Dataset"],"id":"be76a29e-e9c2-411a-a569-04166f074184"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a8496767-2f64-4285-bec4-c6f53a1fd9d2"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, csv_file, transform=None, infer=False):\n","        self.data = pd.read_csv(csv_file)\n","        self.transform = transform\n","        self.infer = infer\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.data.iloc[idx, 1]\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        if self.infer:\n","            if self.transform:\n","                image = self.transform(image=image)['image']\n","            return image\n","\n","        mask_path = self.data.iloc[idx, 2]\n","        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","        mask[mask == 255] = 12 #배경을 픽셀값 12로 간주\n","\n","        if self.transform:\n","            augmented = self.transform(image=image, mask=mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","\n","        return image, mask"],"id":"a8496767-2f64-4285-bec4-c6f53a1fd9d2"},{"cell_type":"markdown","metadata":{"id":"dc955893-22fd-4320-88be-7aa0d790cbd9"},"source":["## Data Loader"],"id":"dc955893-22fd-4320-88be-7aa0d790cbd9"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1695614761924,"user":{"displayName":"‎박동초(엘텍공과대학 휴먼기계바이오공학부)","userId":"15051333855527272603"},"user_tz":-540},"id":"lk6SilpAGFZZ","outputId":"cd04b58f-fcd0-464a-9e24-e2d1ce7c204c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current working directory: /content/drive/.shortcut-targets-by-id/1XBW7z_0X9HZ3TPy2s-sqmFQxzGfrnJTE/2023 Samsung AI Challenge : Camera-Invariant Domain Adaptation/open\n","New current working directory: /content/drive/.shortcut-targets-by-id/1XBW7z_0X9HZ3TPy2s-sqmFQxzGfrnJTE/2023 Samsung AI Challenge : Camera-Invariant Domain Adaptation/open\n"]}],"source":["# 현재 작업 디렉토리 확인\n","current_directory = os.getcwd()\n","print(\"Current working directory:\", current_directory)\n","\n","# 새로운 작업 디렉토리로 변경\n","new_directory = \"/content/drive/MyDrive/2023/open\"  # 새로운 디렉토리 경로를 지정\n","os.chdir(new_directory)\n","\n","# 변경된 현재 작업 디렉토리 확인\n","current_directory = os.getcwd()\n","print(\"New current working directory:\", current_directory)\n"],"id":"lk6SilpAGFZZ"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":809,"status":"ok","timestamp":1695614762729,"user":{"displayName":"‎박동초(엘텍공과대학 휴먼기계바이오공학부)","userId":"15051333855527272603"},"user_tz":-540},"id":"1b708503-2ff9-4584-9d73-40990b3572f8","outputId":"a969868c-b0c7-4ddb-8973-4a6aa5141351"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["transform = A.Compose(\n","    [\n","        A.Resize(224, 224),\n","        A.Normalize(),\n","        ToTensorV2()\n","    ]\n",")\n","\n","dataset = CustomDataset(csv_file='./train_source.csv', transform=transform)\n","dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)"],"id":"1b708503-2ff9-4584-9d73-40990b3572f8"},{"cell_type":"markdown","metadata":{"id":"f42501fc-b573-4893-a7c4-5e280dfdaf09"},"source":["## Define Model"],"id":"f42501fc-b573-4893-a7c4-5e280dfdaf09"},{"cell_type":"code","execution_count":null,"metadata":{"id":"65960bfb-803a-4c40-b713-6f647779e4ea"},"outputs":[],"source":["# U-Net의 기본 구성 요소인 Double Convolution Block을 정의합니다.\n","def double_conv(in_channels, out_channels):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n","        nn.ReLU(inplace=True),\n","        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n","        nn.ReLU(inplace=True)\n","    )\n","\n","# 간단한 U-Net 모델 정의\n","class UNet(nn.Module):\n","    def __init__(self):\n","        super(UNet, self).__init__()\n","        self.dconv_down1 = double_conv(3, 64)\n","        self.dconv_down2 = double_conv(64, 128)\n","        self.dconv_down3 = double_conv(128, 256)\n","        self.dconv_down4 = double_conv(256, 512)\n","\n","        self.maxpool = nn.MaxPool2d(2)\n","        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","\n","        self.dconv_up3 = double_conv(256 + 512, 256)\n","        self.dconv_up2 = double_conv(128 + 256, 128)\n","        self.dconv_up1 = double_conv(128 + 64, 64)\n","\n","        self.conv_last = nn.Conv2d(64, 13, 1) # 12개 class + 1 background\n","\n","    def forward(self, x):\n","        conv1 = self.dconv_down1(x)\n","        x = self.maxpool(conv1)\n","\n","        conv2 = self.dconv_down2(x)\n","        x = self.maxpool(conv2)\n","\n","        conv3 = self.dconv_down3(x)\n","        x = self.maxpool(conv3)\n","\n","        x = self.dconv_down4(x)\n","\n","        x = self.upsample(x)\n","        x = torch.cat([x, conv3], dim=1)\n","\n","        x = self.dconv_up3(x)\n","        x = self.upsample(x)\n","        x = torch.cat([x, conv2], dim=1)\n","\n","        x = self.dconv_up2(x)\n","        x = self.upsample(x)\n","        x = torch.cat([x, conv1], dim=1)\n","\n","        x = self.dconv_up1(x)\n","\n","        out = self.conv_last(x)\n","\n","        return out"],"id":"65960bfb-803a-4c40-b713-6f647779e4ea"},{"cell_type":"markdown","metadata":{"id":"a0895765-fba0-4fd9-b955-a6c0e43012e9"},"source":["## Model Train"],"id":"a0895765-fba0-4fd9-b955-a6c0e43012e9"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"63efb381-98c6-4d9b-a3b6-bd11c7fa8c41","outputId":"4620bad3-4c42-49f6-ecc7-5a1b9a1dc978"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/138 [01:44<?, ?it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-067c8ad5f650>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# model 초기화\n","model = UNet().to(device)\n","\n","# loss function과 optimizer 정의\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# training loop\n","for epoch in range(15):\n","    model.train()\n","    epoch_loss = 0\n","    for images, masks in tqdm(dataloader):\n","        images = images.float().to(device)\n","        masks = masks.long().to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, masks.squeeze(1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}')"],"id":"63efb381-98c6-4d9b-a3b6-bd11c7fa8c41"},{"cell_type":"markdown","metadata":{"id":"c32eb51c-a3fe-4e11-a616-3a717ba16f7e"},"source":["## Inference"],"id":"c32eb51c-a3fe-4e11-a616-3a717ba16f7e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"12371c8b-0c78-47df-89ec-2d8b55c8ea94"},"outputs":[],"source":["test_dataset = CustomDataset(csv_file='./test.csv', transform=transform, infer=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"],"id":"12371c8b-0c78-47df-89ec-2d8b55c8ea94"},{"cell_type":"code","execution_count":null,"metadata":{"id":"355b431c-ac8e-4c40-9046-4d53e4bab14a"},"outputs":[],"source":["with torch.no_grad():\n","    model.eval()\n","    result = []\n","    for images in tqdm(test_dataloader):\n","        images = images.float().to(device)\n","        outputs = model(images)\n","        outputs = torch.softmax(outputs, dim=1).cpu()\n","        outputs = torch.argmax(outputs, dim=1).numpy()\n","        # batch에 존재하는 각 이미지에 대해서 반복\n","        for pred in outputs:\n","            pred = pred.astype(np.uint8)\n","            pred = Image.fromarray(pred) # 이미지로 변환\n","            pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n","            pred = np.array(pred) # 다시 수치로 변환\n","            # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n","            for class_id in range(12):\n","                class_mask = (pred == class_id).astype(np.uint8)\n","                if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n","                    mask_rle = rle_encode(class_mask)\n","                    result.append(mask_rle)\n","                else: # 마스크가 존재하지 않는 경우 -1\n","                    result.append(-1)"],"id":"355b431c-ac8e-4c40-9046-4d53e4bab14a"},{"cell_type":"markdown","metadata":{"id":"36c2cbbb-04f1-4f9c-b4df-4b744dfce046"},"source":["## Submission"],"id":"36c2cbbb-04f1-4f9c-b4df-4b744dfce046"},{"cell_type":"code","execution_count":null,"metadata":{"id":"35ac2a0b"},"outputs":[],"source":["submit = pd.read_csv('./sample_submission.csv')\n","submit['mask_rle'] = result\n","submit"],"id":"35ac2a0b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"da10cb6f-0826-4755-a376-97b695ae8f86"},"outputs":[],"source":["submit.to_csv('./sample_submission.csv', index=False)"],"id":"da10cb6f-0826-4755-a376-97b695ae8f86"}],"metadata":{"accelerator":"TPU","colab":{"provenance":[{"file_id":"1m7BfpLcFmF2w4ca61St2uafS1cqL-nF3","timestamp":1695614486058}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":5}